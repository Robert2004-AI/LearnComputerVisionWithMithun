{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Robert2004-AI/LearnComputerVisionWithMithun/blob/main/ADL_Assigment01_Task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Group No - 44\n",
        "\n",
        "**Group Member Names:**\n",
        "\n",
        "SAKTHI R (2023aa05940)\n",
        "\n",
        "ROBERTSEKAR R (2023aa05823)\n",
        "\n",
        "RAVISHANKAR R (2023aa05171\n",
        "\n",
        "NIMBALKAR PRITEESH DADASAHEB (2023aa05950)"
      ],
      "metadata": {
        "id": "Mk0scK5vLm2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2:\n",
        "\n",
        "Train a single layer autoencoder with linear activation function and appropriately mean and variance normalized input with constraint that encoder weight matrix and decoder weight matrix are transpose w,r,t, each other. Compare the eigenvectors obtained in step 1 with those obtained using the autoencoders. Explain your observations."
      ],
      "metadata": {
        "id": "7fCZnyppMoGu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m9hW9B2fJwh5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.datasets import fetch_openml\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# ---- Load MNIST Dataset ----\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Load the MNIST dataset from OpenML, normalize the pixel values to [0, 1],\n",
        "    and split into training and testing sets.\n",
        "    \"\"\"\n",
        "    mnist = fetch_openml('mnist_784', version=1)  # Fetch MNIST dataset\n",
        "    X = mnist.data / 255.0  # Normalize pixel values to [0, 1]\n",
        "    y = mnist.target.astype(int)  # Convert target labels to integers\n",
        "    # Split the data into training (70%) and testing (30%) sets\n",
        "    return train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Single Layer Linear Autoencoder\n",
        "def build_autoencoder(input_dim, latent_dim):\n",
        "    \"\"\"\n",
        "    Build a single-layer linear autoencoder model.\n",
        "\n",
        "    Parameters:\n",
        "        input_dim (int): Dimensionality of the input data.\n",
        "        latent_dim (int): Dimensionality of the latent (compressed) space.\n",
        "\n",
        "    Returns:\n",
        "        autoencoder (Model): Compiled autoencoder model.\n",
        "    \"\"\"\n",
        "    # Define the input layer with the same shape as the input data\n",
        "    input_layer = layers.Input(shape=(input_dim,))\n",
        "\n",
        "    # Encoder: Compress input to latent space of size 'latent_dim' with linear activation\n",
        "    encoded = layers.Dense(latent_dim, activation='linear')(input_layer)\n",
        "\n",
        "    # Decoder: Reconstruct input from the latent space with linear activation\n",
        "    decoded = layers.Dense(input_dim, activation='linear')(encoded)\n",
        "\n",
        "    # Create the autoencoder model combining encoder and decoder\n",
        "    autoencoder = models.Model(input_layer, decoded)\n",
        "\n",
        "    # Compile the model with Adam optimizer and Mean Squared Error (MSE) loss\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "    return autoencoder\n",
        "\n",
        "\n",
        "# ---- Main Execution ----\n",
        "\n",
        "latent_dim = 50  # Set the latent space dimensionality for the autoencoder\n",
        "pca = PCA(n_components=0.95)  # Initialize PCA to retain variance\n",
        "# Fit PCA to the training data\n",
        "pca.fit(X_train)  # Compute PCA on the training data\n",
        "# Build the autoencoder with input dimensionality equal to the number of features in the dataset\n",
        "autoencoder = build_autoencoder(X_train.shape[1], latent_dim)\n",
        "\n",
        "# Train the autoencoder using the training data as both input and target\n",
        "# The goal is to reconstruct the input while learning a compressed representation\n",
        "print(\"Training Single-Layer Linear Autoencoder...\")\n",
        "autoencoder.fit(X_train, X_train, epochs=10, batch_size=256, shuffle=True)\n",
        "\n",
        "# Extract encoder weights (first layer's weights) for comparison with PCA components\n",
        "encoder_weights = autoencoder.layers[1].get_weights()[0]\n",
        "\n",
        "# Compare encoder weights with PCA eigenvectors\n",
        "# PCA eigenvectors represent the directions of maximum variance, while autoencoder weights approximate them\n",
        "print(\"Comparing Autoencoder Weights with PCA Eigenvectors\")\n",
        "# Select the top 'latent_dim' PCA components\n",
        "pca_components = pca.components_[:latent_dim]\n",
        "print(f\"PCA Eigenvectors Shape: {pca_components.shape}, Autoencoder Weights Shape: {encoder_weights.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCnM7VvtUP-1",
        "outputId": "3016a2e2-b45b-4de9-e0c0-4d9da1f08eb0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Single-Layer Linear Autoencoder...\n",
            "Epoch 1/10\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0653\n",
            "Epoch 2/10\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0198\n",
            "Epoch 3/10\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0145\n",
            "Epoch 4/10\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0128\n",
            "Epoch 5/10\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123\n",
            "Epoch 6/10\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0121\n",
            "Epoch 7/10\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0120\n",
            "Epoch 8/10\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0119\n",
            "Epoch 9/10\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119\n",
            "Epoch 10/10\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119\n",
            "Comparing Autoencoder Weights with PCA Eigenvectors\n",
            "PCA Eigenvectors Shape: (50, 784), Autoencoder Weights Shape: (784, 50)\n"
          ]
        }
      ]
    }
  ]
}